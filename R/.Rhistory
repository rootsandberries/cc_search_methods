variable == "grey_search"|
variable == "grey_url"|
variable == "forward_method"|
variable == "refman_software"|
variable == "deduplicate"|
variable == "num_records")
#Report variables for no IS
#Report variables for IS coauthor
report_nois <- none_impact %>% filter(variable == "strategy_all"|
variable == "db_list_gp"|
variable == "db_platform"|
variable == "date_searches"|
variable == "grey_list"|
variable == "grey_search"|
variable == "grey_url"|
variable == "forward_method"|
variable == "refman_software"|
variable == "deduplicate"|
variable == "num_records")
#Merge all three dataframes
report_is_table1 <- merge(report_nois, report_mention, by = "variable", all = TRUE)
report_is_table <- merge(report_is_table1, report_coauth, by = "variable", all = TRUE)
#Recode variable names for table
report_is_table_rename <- report_is_table %>%
mutate(variable = case_when(
variable == "date_searches" ~ "Search dates reported",
variable == "db_list_gp" ~ "All databases and sub-databases listed",
variable == "db_platform" ~ "Database platform reported",
variable == "deduplicate" ~ "Deduplication method reported",
variable == "forward_method" ~ "Method for forward citation searching described",
variable == "grey_list" ~ "grey lit sources listed",
variable == "grey_search" ~ "grey lit search reported",
variable == "grey_url" ~ "grey lit URLs reported",
variable == "refman_software" ~ "Reference management software reported",
variable == "strategy_all" ~ "All search strategies reported",
variable == "num_records" ~ "Number of records per database reported"
))
#Reorder with custom order
report_custom_order <- c("All search strategies reported","All databases and sub-databases listed","Database platform reported",
"Search dates reported", "grey lit sources listed", "grey lit search reported",
"grey lit URLs reported", "Method for forward citation searching described",
"Reference management software reported", "Deduplication method reported",
"Number of records per database reported")
report_is_table_rename <- report_is_table_rename %>%
mutate(variable = factor(variable, levels = report_custom_order)) %>%
arrange(variable)
write_csv(report_is_table_rename, here("./data_outputs/ccmethods_isinvolve_report_table.csv"))
#Reporting Table
is_table_df_report <- read.csv(here("./data_outputs/ccmethods_isinvolve_report_table.csv"))
is_table_report <- is_table_df_report %>% gt()
gt_tbl_report <-
gt(is_table_df_report) |>
tab_header(
title = "",
subtitle = "Reporting of searches"
) |>
tab_spanner(
label = "No IS Involvement (n=29)",
columns = c(count.x, percentage.x)
) |>
tab_spanner(
label = "IS consulted (n=33)",
columns = c(count.y, percentage.y)
) |>
tab_spanner(
label = "IS co-author (n=24)",
columns = c(count, percentage)
) |>
tab_options(
heading.subtitle.font.size = 16
) %>%
cols_label(variable="", count.x = "No.", percentage.x="%", count.y = "No.", percentage.y="%", count = "No.", percentage="%")
gt_tbl_report
#Save to image file
gt_tbl_report |> gtsave(here("./plots/report_is_table.png"), expand = 10)
##Figure 7B. Line graph for IS impact on reporting variables----
#Subset only percentage columns from conduct_is_table
report_is_chart_df <- report_is_table[, c(1,3, 5, 7)]
#Transpose to long format grouping percentage columns by IS involvement
report_is_chart_long <- report_is_chart_df %>%
pivot_longer(cols = c(percentage.x, percentage.y, percentage),
names_to = "group",
values_to = "percentage")
#Rename group names
report_is_chart_long <- report_is_chart_long %>%
mutate(group = case_when(
group == "percentage.x" ~ "No IS",
group == "percentage.y" ~ "IS consulted",
group == "percentage" ~ "IS co-author"))
report_is_chart_long <- report_is_chart_long %>%
mutate(group = factor(group, levels = c("No IS", "IS consulted", "IS co-author")))
#Recode variable names for chart legend
report_is_chart_renamed <- report_is_chart_long %>%
mutate(variable = case_when(
variable == "date_searches" ~ "Search dates",
variable == "db_list_gp" ~ "Database names",
variable == "db_platform" ~ "Database platform",
variable == "deduplicate" ~ "Dedup method",
variable == "forward_method" ~ "Forward citation method",
variable == "grey_list" ~ "grey lit sources",
variable == "grey_search" ~ "grey lit search",
variable == "grey_url" ~ "grey lit URLs",
variable == "refman_software" ~ "Ref mgmt software",
variable == "strategy_all" ~ "All search strategies",
variable == "num_records" ~ "Number of database results"
))
#Reorder so that the legend list matches the order of values in the No IS column
custom_order_isrp <- c("grey lit sources", "Search dates", "Forward citation method", "Database names", "Database platform", "Ref mgmt software", "All search strategies", "grey lit search", "Number of database results", "grey lit URLs", "Dedup method")
report_is_chart_renamed$variable <- factor(report_is_chart_renamed$variable, levels = custom_order_isrp)
#Create distinguishable palette for 11 variables
my_palette_11 <- c25 <- c(
"#E31A1C", # red
"green4",
"#6A3D9A", # purple
"#FF7F00", # orange
"black", "gold1", "deeppink1", "blue1",
"darkturquoise", "green1", "brown"
)
#Plot change in percentage over groups
pt_report_is <- ggplot(report_is_chart_renamed, aes(x = group, y = percentage, color = variable, group = variable)) +
geom_line() +
geom_point() +
guides(fill = guide_legend(title = NULL)) +
labs(title = "",
x = "",
y = "Percent of reviews",
color = "Variable") +
theme_minimal() +
theme(legend.title=element_blank()) +
scale_color_manual(values = my_palette_14) #+
#theme(text = element_text(size=13))
ggsave(here("./plots/fig7b.png"), plot = pt_report_is, width = 6, height = 4, units = "in", dpi = 300)
#Save to image file
gt_tbl_conduct |> gtsave(here("./plots/conduct_is_table.png"), expand = 10)
ccmethods_IS_coauthor <- ccmethods_data_is_sub %>% filter(infosp_coauthor == 'yes')
#Percentages
coauthor_impact_per <- ccmethods_IS_coauthor %>%
summarise(across(everything(), ~ mean(. == 'yes', na.rm = TRUE) * 100, .names = '{.col}')) %>%
pivot_longer(everything(), names_to = "variable", values_to = "percentage") %>%
mutate(percentage = round(percentage, 1))
#write.csv(coauthor_impact_per, "coauthor_impact_per.csv")
#Counts
coauthor_impact_count <- colSums(ccmethods_IS_coauthor == "yes", na.rm = TRUE)
coauthor_impact_count_df <- data.frame(variable = names(coauthor_impact_count), count = coauthor_impact_count)
#write.csv(coauthor_impact_count_df, "coauthor_impact_count.csv")
#Combine percentage and counts tables by variable name
coauthor_impact <- merge(coauthor_impact_count_df, coauthor_impact_per, by = 'variable', all = TRUE)
#Was mentioned in methods or acknowledgment, but not co-author
ccmethods_IS_mention <- ccmethods_data_is_sub %>% filter(infosp_involve == 'yes', infosp_coauthor == 'no')
#Percentages
mention_impact_per <- ccmethods_IS_mention %>%
summarise(across(everything(), ~ mean(. == 'yes', na.rm = TRUE) * 100, .names = '{.col}')) %>%
pivot_longer(everything(), names_to = "variable", values_to = "percentage") %>%
mutate(percentage = round(percentage, 1))
#write.csv(mention_impact, "mention_impact.csv")
#Counts
mention_impact_count <- colSums(ccmethods_IS_mention == "yes", na.rm = TRUE)
mention_impact_count_df <- data.frame(variable = names(mention_impact_count), count = mention_impact_count)
#write.csv(mention_impact_count_df, "mention_impact_count.csv")
#Combine percentage and counts tables by variable name
mention_impact <- merge(mention_impact_count_df, mention_impact_per, by = 'variable', all = TRUE)
#Is involved in some way
ccmethods_IS_involve <- ccmethods_data_is_sub %>% filter(infospec == 'yes')
#Percentage
involve_impact_per <- ccmethods_IS_involve %>%
summarise(across(everything(), ~ mean(. == 'yes', na.rm = TRUE) * 100, .names = '{.col}')) %>%
pivot_longer(everything(), names_to = "variable", values_to = "percentage") %>%
mutate(percentage = round(percentage, 1))
#write.csv(involve_impact, "involve_impact.csv")
#Is not an author
ccmethods_IS_no_author <- ccmethods_data_is_sub %>% filter(infosp_coauthor == 'no')
#Percentages
no_author_impact_per <- ccmethods_IS_no_author %>%
summarise(across(everything(), ~ mean(. == 'yes', na.rm = TRUE) * 100, .names = '{.col}')) %>%
pivot_longer(everything(), names_to = "variable", values_to = "percentage") %>%
mutate(percentage = round(percentage, 1))
#write.csv(no_author_impact, "no_author_impact.csv")
#No involvement at all
ccmethods_IS_none <- ccmethods_data_is_sub %>% filter(infospec == 'no')
#Percentages
none_impact_per <- ccmethods_IS_none %>%
summarise(across(everything(), ~ mean(. == 'yes', na.rm = TRUE) * 100, .names = '{.col}')) %>%
pivot_longer(everything(), names_to = "variable", values_to = "percentage") %>%
mutate(percentage = round(percentage, 1))
#write.csv(none_impact, "none_impact.csv")
#Count
none_impact_count <- colSums(ccmethods_IS_none == "yes", na.rm = TRUE)
none_impact_count_df <- data.frame(variable = names(none_impact_count), count = none_impact_count)
#write.csv(none_impact_count_df, "none_impact_count.csv")
#Combine percentage and counts tables by variable name
none_impact <- merge(none_impact_count_df, none_impact_per, by = 'variable', all = TRUE)
#Total percent of each variable with yes value
percent_yes <- ccmethods_data_is_sub %>%
summarise(across(everything(), ~ mean(. == 'yes', na.rm = TRUE) * 100, .names = 'Percent_{.col}')) %>%
pivot_longer(everything(), names_to = "Variable", values_to = "Percentage") %>%
mutate(Percentage = round(Percentage, 1))
#write.csv(percent_yes, "percent_yes.csv")
#Assemble tables from above outputs
##Supplementary File 5: Table of conduct variables by IS involvement
#Subset conduct columns only for coauthor, mention and no involvement
#Conduct variables for IS coauthor
conduct_coauth <- coauthor_impact %>% filter(variable == "boolean"|
variable == "subhead"|
variable == "keyword_var"|
variable == "phrase"|
variable == "syntax"|
variable == "free_gs"|
variable == "engine_google"|
variable == "handsearch"|
variable == "experts"|
variable == "backward"|
variable == "forward"|
variable == "reviews"|
variable == "update_search"|
variable == "kugley")
#Conduct variables for IS mention
conduct_mention <- mention_impact %>% filter(variable == "boolean"|
variable == "subhead"|
variable == "keyword_var"|
variable == "phrase"|
variable == "syntax"|
variable == "free_gs"|
variable == "engine_google"|
variable == "handsearch"|
variable == "experts"|
variable == "backward"|
variable == "forward"|
variable == "reviews"|
variable == "update_search"|
variable == "kugley")
#Conduct variables for no IS
#Conduct variables for IS coauthor
conduct_nois <- none_impact %>% filter(variable == "boolean"|
variable == "subhead"|
variable == "keyword_var"|
variable == "phrase"|
variable == "syntax"|
variable == "free_gs"|
variable == "engine_google"|
variable == "handsearch"|
variable == "experts"|
variable == "backward"|
variable == "forward"|
variable == "reviews"|
variable == "update_search"|
variable == "kugley")
#Merge all three dataframes
conduct_is_table1 <- merge(conduct_nois, conduct_mention, by = "variable", all = TRUE)
conduct_is_table <- merge(conduct_is_table1, conduct_coauth, by = "variable", all = TRUE)
#Rename variable names for table
conduct_is_table_rename <- conduct_is_table %>%
mutate(variable = case_when(
variable == "backward" ~ "Backward citation searching conducted",
variable == "boolean" ~ "Boolean operators used correctly",
variable == "engine_google" ~ "Google searched",
variable == "experts" ~ "Experts contacted",
variable == "forward" ~ "Forward citation searching conducted",
variable == "free_gs" ~ "Google Scholar searched",
variable == "handsearch" ~ "Handsearches conducted",
variable == "keyword_var" ~ "Keyword variants used",
variable == "kugley" ~ "Kugley et al. (2017) guidance cited",
variable == "phrase" ~ "Phrase searching used correctly",
variable == "reviews" ~ "References of related reviews searched",
variable == "subhead" ~ "Database subj heading/thesauri used",
variable == "syntax" ~ "Database syntax used correctly",
variable == "update_search" ~ "Search updated prior to publication"
))
#Reorder with custom order
conduct_custom_order <- c("Boolean operators used correctly","Database subj heading/thesauri used","Keyword variants used",
"Phrase searching used correctly", "Database syntax used correctly", "Google Scholar searched",
"Google searched", "Handsearches conducted","Experts contacted",
"Backward citation searching conducted", "Forward citation searching conducted",
"References of related reviews searched", "Search updated prior to publication", "Kugley et al. (2017) guidance cited")
conduct_is_table_rename <- conduct_is_table_rename %>%
mutate(variable = factor(variable, levels = conduct_custom_order)) %>%
arrange(variable)
write_csv(conduct_is_table_rename, here("./data_outputs/ccmethods_isinvolve_conduct_table.csv"))
#Conduct Table
is_table_df <- read.csv(here("./data_outputs/ccmethods_isinvolve_conduct_table.csv"))
is_table <- is_table_df %>% gt()
gt_tbl_conduct <-
gt(is_table_df) |>
tab_header(
title = "",
subtitle = "Conduct of searches"
) |>
tab_spanner(
label = "No IS Involvement (n=29)",
columns = c(count.x, percentage.x)
) |>
tab_spanner(
label = "IS consulted (n=33)",
columns = c(count.y, percentage.y)
) |>
tab_spanner(
label = "IS co-author (n=24)",
columns = c(count, percentage)
) |>
tab_options(
heading.subtitle.font.size = 16
) %>%
cols_label(variable="", count.x = "No.", percentage.x="%", count.y = "No.", percentage.y="%", count = "No.", percentage="%")
gt_tbl_conduct
#Save to image file
gt_tbl_conduct |> gtsave(here("./plots/conduct_is_table.png"), expand = 10)
library(lubridate)
#Import data
ccmethods_data <- read.csv(here("./data/CC-methods-data-extraction-final-20220222-clean-recode.csv"), na = "NA")
#Import data
ccmethods_data <- read.csv(here("./data/CC-methods-data-extraction-final-20240222-clean-recode.csv"), na = "NA")
ccmethods_data$pub_date <- make_date(ccmethods_data$pub_year, ccmethods_data$pub_mo)
ccmethods_data$search_date <- make_date(ccmethods_data$search_year, ccmethods_data$search_mo)
#calculate the number of days elapsed between publication date and last search date and convert to number of months
ccmethods_data$search_lag <- difftime(ccmethods_data$pub_date, ccmethods_data$search_date, units = "days") %>%
as.numeric() / 30.44
#round to integer
ccmethods_data$search_lag <- round(ccmethods_data$search_lag)
#Simple histogram plot of time lags
pt_hist_timelag <- ggplot(ccmethods_data, aes(x = search_lag)) +
geom_histogram(color="black", fill="lightgray", binwidth = 3) + theme_light() +
labs(x = str_wrap("Number of months between search date and publication date", width=50), y="Number of reviews") +
scale_y_continuous(breaks = seq(from = 0, to = 12, by = 2), limits = c(0, 12)) +
scale_x_continuous(breaks = seq(from = 0, to = 100, by = 25), limits = c(0, 100)) #+
#theme(text = element_text(size=15))
ggsave(here("./plots/fig8a.png"), plot = pt_hist_timelag, width = 6, height = 4, units = "in", dpi = 300)
mydata_sep_lag <- separate_rows(ccmethods_data, cg, sep=";")
#Remove groups with very few reviews
mydata_sep_lag <- mydata_sep_lag %>% subset(cg != "Nutrition") %>%
subset(cg != "Methods") %>% subset(cg != "Knowledge Translation and Implementation")
#Plot boxplot by coordinating group and label outliers
pt_box_timelag <- ggplot(mydata_sep_lag, aes(x = cg, y = search_lag)) +
geom_boxplot() +
geom_text(data = mydata_sep_lag %>%
group_by(cg) %>%
filter(search_lag < quantile(search_lag, 0.25) - 1.5*IQR(search_lag) | search_lag > quantile(search_lag, 0.75) + 1.5*IQR(search_lag)),
aes(x = cg, y = search_lag, label = round(search_lag, 2)),
hjust = 1.5, vjust = 0.5, size = 4) +
scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) +
labs(x="Coordinating Group", y=("Number of months"))
ggsave(here("./plots/fig8b.png"), plot = pt_box_timelag, width = 6, height = 4, units = "in", dpi = 300)
##In text results----
#Percent reporting deduplication methods
prop.table(table(ccmethods_data$deduplicate)) * 100
table(ccmethods_data$deduplicate, useNA = "always")
prop.table(table(ccmethods_data$refman_software)) * 100
prop.table(table(ccmethods_data$refman_software)) * 100
table(ccmethods_data$refman_software, useNA = "always")
just_ref_software <- ccmethods_data %>% subset(refman_software == "yes") %>%
select(refman_software_text)
write.csv(just_ref_software, here("./data_outputs/refman_software.csv"))
ref_tools <- read.csv(here("./data_outputs/refman_software_clean.csv"))
nrow(ref_tools)
ref_tools %>%
group_by(tool) %>%
summarize(count = n())
#Number of reviews mentioning that search was updated
table(ccmethods_data$update_search)
prop.table(table(ccmethods_data$update_search)) * 100
##In text results----
#Get median, mean, min and max of time lag
summary(ccmethods_data$search_lag)
myaov <- aov(search_lag ~ cg, data = mydata_sep_lag)
summary(myaov)
anova(myaov)
twodb_num_yes <- ccmethods_data %>%
summarize(twodb_num_yes = sum(two_db == 'yes', na.rm = TRUE)) %>%
pull(twodb_num_yes)
twodb_perc_yes <- ccmethods_data %>%
summarize(twodb_perc_yes = mean(two_db == 'yes', na.rm = TRUE) * 100) %>%
pull(twodb_perc_yes) |> round(digits=1)
#Provided search strategy
stratone_num_yes <- ccmethods_data %>%
summarize(stratone_num_yes = sum(strategy_one == 'yes', na.rm = TRUE)) %>%
pull(stratone_num_yes)
stratone_perc_yes <- ccmethods_data %>%
summarize(stratone_perc_yes = mean(strategy_one == 'yes', na.rm = TRUE) * 100) %>%
pull(stratone_perc_yes) |> round(digits=1)
#Justified restrictions
#Create new justification column where NA is yes (for use below)
ccmethods_data$limit_just_amstar <- ifelse(is.na(ccmethods_data$limit_just), "yes", ccmethods_data$limit_just)
limjust_num_yes <- ccmethods_data %>%
summarize(limjust_num_yes = sum(limit_just_amstar == 'yes', na.rm = TRUE)) %>%
pull(limjust_num_yes)
limjust_perc_yes <- ccmethods_data %>%
summarize(limjust_perc_yes = mean(limit_just_amstar == 'yes', na.rm = TRUE) * 100) %>%
pull(limjust_perc_yes) |> round(digits=1)
#Conducted backward citation searching
bw_num_yes <- ccmethods_data %>%
summarize(bw_num_yes = sum(backward == 'yes', na.rm = TRUE)) %>%
pull(bw_num_yes)
bw_perc_yes <- ccmethods_data %>%
summarize(bw_perc_yes = mean(backward == 'yes', na.rm = TRUE) * 100) %>%
pull(bw_perc_yes) |> round(digits=1)
#Searched trial and study registries
trreg_yes <- sum(ccmethods_data$trials == "yes" | ccmethods_data$registries == "yes")
trreg_percent <- trreg_yes/nrow(ccmethods_data)*100 |> round(digits=2)
#Create new column combining trials and registries (for use below)
ccmethods_data$trial_reg <- ifelse(ccmethods_data$trials == "yes" | ccmethods_data$registries == "yes", "yes",
ifelse(ccmethods_data$trials != "yes" & ccmethods_data$registries != "yes", "no", "unclear"))
#Consulted experts
exp_num_yes <- ccmethods_data %>%
summarize(exp_num_yes = sum(experts == 'yes', na.rm = TRUE)) %>%
pull(exp_num_yes)
exp_perc_yes <- ccmethods_data %>%
summarize(exp_perc_yes = mean(experts == 'yes', na.rm = TRUE) * 100) %>%
pull(exp_perc_yes) |> round(digits=1)
#Searched grey literature
grey_yes <- sum(ccmethods_data$conf_proc == "yes" | ccmethods_data$theses == "yes" | ccmethods_data$govt == "yes" | ccmethods_data$ngo == "yes")
grey_percent <- grey_yes/nrow(ccmethods_data)*100 |> round(digits=1)
#Create new column combining all grey lit columns (for use below)
ccmethods_data$all_grey <- ifelse(ccmethods_data$conf_proc == "yes" | ccmethods_data$theses == "yes" | ccmethods_data$govt == "yes" | ccmethods_data$ngo == "yes", "yes",
ifelse(ccmethods_data$conf_proc != "yes" & ccmethods_data$theses != "yes" & ccmethods_data$govt != "yes" & ccmethods_data$ngo != "yes", "no", "unclear"))
#Conducted search within 24 months of completion
#Create new columns with proper date formats from year and month
ccmethods_data$pub_date <- make_date(ccmethods_data$pub_year, ccmethods_data$pub_mo)
ccmethods_data$search_date <- make_date(ccmethods_data$search_year, ccmethods_data$search_mo)
#calculate the number of days elapsed between publication date and last search date and convert to month
ccmethods_data$search_lag <- difftime(ccmethods_data$pub_date, ccmethods_data$search_date, units = "days") %>%
as.numeric() / 30.44
#round to integer
ccmethods_data$search_lag <- round(ccmethods_data$search_lag)
#number of reviews where search lag is less than or equal to 24 months
lag_24 <- sum(ccmethods_data$search_lag <= 24)
lag_24_percent <- lag_24/nrow(ccmethods_data)*100 |> round(digits=1)
#Partial Yes adherence: at least 2 databases, provided at least one search strategy, justified restrictions
ccmethods_data$amstar_partial_yes <- ifelse(ccmethods_data$two_db == "yes" & ccmethods_data$strategy_one == "yes" & ccmethods_data$limit_just_amstar == "yes", "yes", "no")
partial_yes <- sum(ccmethods_data$amstar_partial_yes == "yes")
partial_yes_only <- partial_yes - full_yes
partial_yes_perc <- ((partial_yes_only/nrow(ccmethods_data)) * 100) |> round(digits=1)
#Full Yes adherence: all partial plus backward citation searching, searched trials/registries, consulted experts, searched grey literature, conducted search within 24 months
ccmethods_data$amstar_full_yes <- ifelse(ccmethods_data$amstar_partial_yes == "yes" & ccmethods_data$backward == "yes" & ccmethods_data$experts == "yes" & ccmethods_data$all_grey == "yes" & ccmethods_data$search_lag <= 24, "yes", "no")
full_yes <- sum(ccmethods_data$amstar_full_yes == "yes")
full_yes_perc <- ((full_yes/nrow(ccmethods_data)) * 100) |> round(digits=1)
#Calculate number and percent of No ratings (total number of reviews minus number of Partial Yes ratings)
no_amst_num <- nrow(ccmethods_data) - partial_yes
no_amst_perc <- ((no_amst_num/nrow(ccmethods_data)) * 100) |> round(digits=1)
#AMSTAR table
#Create dataframe from values above
number <- c(twodb_num_yes, stratone_num_yes, limjust_num_yes, bw_num_yes, trreg_yes, exp_num_yes, grey_yes, lag_24, full_yes, partial_yes_only, no_amst_num)
percent <- c(twodb_perc_yes, stratone_perc_yes, limjust_perc_yes, bw_perc_yes, trreg_percent, exp_perc_yes, grey_percent, lag_24_percent, full_yes_perc, partial_yes_perc, no_amst_perc)
criteria <- c("Searched at least 2 databases", "Provided search strategy", "Justified publication restrictions", "Searched the reference lists of included studies", "Searched trial/study registries", "Included/consulted content experts", "Searched for grey literature", "Conducted search within 24 months", "Yes", "Partial Yes", "No")
is_table_amstar <- data.frame(criteria = criteria, number = number, percent = percent)
is_table_amstar$percent <- round(is_table_amstar$percent, 1)
#Prepare dataframe as table for gt
is_table <- is_table_amstar %>% gt()
gt_tbl_amstar <-
gt(is_table_amstar) |>
tab_spanner(
label = "Meets AMSTAR 2 criteria",
columns = c(number, percent)
) |>
tab_style(
style = list(
cell_fill(color = "lightcyan"),
cell_text(weight = "bold")
),
locations = cells_body(
rows = criteria == "Yes"
)
) |>
tab_style(
style = list(
cell_fill(color = "lightcyan"),
cell_text(weight = "bold")
),
locations = cells_body(
rows = criteria == "No"
)
) |>
tab_style(
style = list(
cell_fill(color = "lightcyan"),
cell_text(weight = "bold")
),
locations = cells_body(
rows = criteria == "Partial Yes"
)
) |>
cols_align(
align = "center",
columns = number
) |>
cols_align(
align = "center",
columns = percent
) |>
tab_options(
heading.subtitle.font.size = 16
) %>%
cols_label(criteria="", number = "Number of reviews", percent ="Percent of reviews (%)")
gt_tbl_amstar
#Save to image file (note: may need to restart RStudio to get this to work)
gt_tbl_amstar |> gtsave(here("./plots/amstar_table.png"), expand = 10)
table(ccmethods_data_is$infosp_involve)
#Percent searching at least 2 relevant databases
prop.table(table(ccmethods_data$two_db)) * 100
#Percent reporting website urls
table(ccmethods_data$grey_list, useNA = "always")
#Percent reporting grey lit sources
table(ccmethods_data$grey_list, useNA = "always")
prop.table(table(ccmethods_data$grey_list)) * 100
table(ccmethods_data$db_platform, useNA = "always")
prop.table(table(ccmethods_data$db_platform)) * 100
prop.table(table(ccmethods_data$date_range)) * 100
##In text results ----
##More detail about database descriptions
table(ccmethods_data$strategy_one, useNA = "always")
prop.table(table(ccmethods_data$strategy_one)) * 100
prop.table(table(ccmethods_data$strategy_all)) * 100
prop.table(table(ccmethods_data$handsearch)) * 100
prop.table(table(ccmethods_data$forward)) * 100
prop.table(table(ccmethods_data_is$infosp_coauthor)) * 100
